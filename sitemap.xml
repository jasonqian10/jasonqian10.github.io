<search>
    
     <entry>
        <title>【Hadoop索引】Mapreduce进行solr索引实战</title>
        <url>https://jasonqian10.github.io/post/mapreduce-index-2/</url>
        <categories>
          <category>Hadoop</category>
        </categories>
        <tags>
          <tag>hadoop</tag><tag>mapreduce</tag><tag>solr</tag>
        </tags>
        <content type="html">  MapReduce如何做solr索引 如何用MapReduce做solr索引？ 网上现在使用MapReduce做solr索引的方式实战比较少，比较多的尝试有如下两种
 Cloudera MapReduceIndexerTool  cloudera提供了基于morphline的索引工具SDK，solr也做了集成，在solr/contrib/map-reduce包。入口类为 MapReduceIndexerTool，详细使用可以参考
https://docs.cloudera.com/documentation/enterprise/latest/topics/search_mapreduceindexertool.html
 running solr on HDFS  这个是solr支持的索引到HDFS上，其实与MapReduce没有啥关系。细节见
https://lucene.apache.org/solr/guide/6_6/running-solr-on-hdfs.html
Cloudera MapReduceIndexerTool的方式我们也尝试过，发现有些定制化的功能无法满足，而且solr在6.6版本之后移除了map-reduce模块（https://issues.apache.org/jira/browse/SOLR-9221 ），原因是与Hadoop版本兼容问题。所以最后放弃使用了。但是solr/contrib/map-reduce中很多源码是值得参考的，我们在开发过程了也借鉴了很多。
架构  备注: 我们使用aws emr做Hadoop集群，所以会使用一些 aws的服务
 流程其实很清晰，主要有以下几部分
 Input  做索引的输入文件，存在在aws s3或者hdfs。
job client提交job任务，其中准备MapReduce过程中需要使用的各种参数。
 Map  map阶段完成solrDoucment的转换，其map的输出为，其中shardNum表示solrDocument所在solr集群中哪个shard。因为我们使用embedSolr作为solrServer进行index，并未使用https的方式进行index，所以分shard的逻辑需要在map中进行计算。算出shardNum，作为map输出的key。这样在后续shuffle，sort过程中MapReduce框架会把key相同的所有solrDoucment拷贝到同一reduce task的节点上。
 Reduce  包含前置流程shuffle和sort，目的是把Hadoop集群各个节点上map输出的solrDoucment按key的不同拷贝并排序到对应的reduce task节点上。
Reduce task就纯粹完成solr index，reduce container的jvm中启动EmbeddedSolr作为solr server。
 output  solr索引文件支持输出到hdfs或者disk（只需在solrconfig.xml中配置即可），两种方式我们都尝试过，index速度方面，存储到disk更快一些。一般建议使用hdfs，因为使用了Hadoop，最好使用它的分布式存储系统。
遇到一些问题  MapReduce的container数量如何分配？  这里有几个概念： MapReduce集群同时可以运行的
</content>
    </entry>
    
     <entry>
        <title>【Hadoop索引】我理解的hadoop</title>
        <url>https://jasonqian10.github.io/post/mapreduce-index-1/</url>
        <categories>
          <category>Hadoop</category>
        </categories>
        <tags>
          <tag>hadoop</tag><tag>mapreduce</tag><tag>solr</tag>
        </tags>
        <content type="html"> 【Hadoop索引】将介绍如何使用Hadoop框架进行solr索引。本文档介绍我学习使用Hadoop后对其的理解。
为什么使用Hadoop来做solr索引？ 这与Hadoop特点有关，hadoop适用于处理大数据并行计算，提高solr索引速度。map阶段转换solr document，reduce阶段进行solr add操作。MapReduce流程契合solr索引的流程。
Hadoop概念 官方概念 The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models.
总结：处理大数据、分布式集群、可编程计算框架
Hadoop 的核心组件 Hadoop由1.0和2.0两个架构版本，2.0最大的变化就是引入YARN这个资源调度框架，更加精细化的分配和调度资源。这里主要以当前最新的2.0展开。感兴趣的同学可以自行了解一下两者差异。
 HDFS：分布式文件系统
 Mapreduce：分布式运算编程框架
 YARN：运算资源调度系统
  简单描述一下三者关系：自定义的MapReduce程序（Java进程），通过YARN框架分配资源来运行这个MapReduce程序，MapReduce程序中输出存储到HDFS。
YARN框架 Apache Hadoop YARN （Yet Another Resource Negotiator，另一种资源协调者）是一种新的 Hadoop 资源管理器，它是一个通用资源管理系统，可为上层应用提供统一的资源管理和调度。它将资源管理和处理组件分开，它的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。
YARN框架几个重要组件/概念  ResourceManager(RM)  ResourceManager包含两个主要的组件：定时调用器(Scheduler)以及应用管理器(ApplicationsManager (AsM))。
 定时调度器(Scheduler)：这个组件完全是插拔式的，用户可以根据自己的需求实现不同的调度器，目前YARN提供了FIFO、容量以及公平调度器。这个组件的唯一功能就是给提交到集群的应用程序分配资源，并且对可用的资源和运行的队列进行限制。Scheduler并不对作业进行监控，并且它不保证会重启由于应用程序本身或硬件出错而执行失败的应用程序。
 为所有AM分配资源
 应用管理器(ApplicationsManager (AsM))：这个组件用于管理整个集群应用程序的application masters，负责接收应用程序的提交；为application master启动提供资源；监控应用程序的运行进度以及在应用程序出现故障时重启它。
 用于管理所有AM
   NodeManager(NM)  是YARN中每个节点上的代理，它管理Hadoop集群中单个计算节点，根据相关的设置来启动容器的。NodeManager会定期向ResourceManager发送心跳信息来更新其健康状态。同时其也会监督Container的生命周期管理，监控每个Container的资源使用（内存、CPU等）情况，追踪节点健康状况，管理日志和不同应用程序用到的附属服务（auxiliary service）。
 ApplicationMaster(AM)  ApplicationMaster是应用程序级别的，每个ApplicationMaster管理运行在YARN上的应用程序。YARN 将 ApplicationMaster看做是第三方组件，ApplicationMaster负责和ResourceManager scheduler协商资源，并且和NodeManager通信来运行相应的task。ResourceManager 为 ApplicationMaster 分配容器，这些容器将会用来运行task。ApplicationMaster 也会追踪应用程序的状态，监控容器的运行进度。当容器运行完成， ApplicationMaster 将会向 ResourceManager 注销这个容器；如果是整个作业运行完成，其也会向 ResourceManager 注销自己，这样这些资源就可以分配给其他的应用程序使用了。
 Container容器  Container是一个逻辑上的概念。与特定节点绑定的，其包含了内存、CPU磁盘等逻辑资源。不过在现在的容器实现中，这些资源只包括了内存和CPU。容器是由 ResourceManager scheduler 服务动态分配的资源构成。容器授予 ApplicationMaster 使用特定主机的特定数量资源的权限。ApplicationMaster 也是在容器中运行的，其在应用程序分配的第一个容器中运行。
YARN框架执行流程 1.Client执行main()函数中runjob()，向yarn提交job，开启作业。
 这里client jvm是个独立运行的Java进程，跑在Hadoop集群的master节点上。
 2.Client向RM发送作业请求同时RM将作业id以及jar包存放路径返回给Client。
3.Client会把Jar路径为前缀作业id为后缀作为唯一存放路径，将jar包以及输入分片写入到HDFS集群中。
 2,3两步都是Hadoop框架来做的，用户只需执行1即可。注意，这里框架只会默认上传MapReduce程序jar包和输入分片文件。如果用户运行MapReduce程序过程中还需其他的jar包、配置文件等，需要在1中自行上传，以及在task运行起来后自行获取。
 4.Client再次将Jar存放地址(更为详细的描述)提交给RM。
5.RM将其放入调度器，向NM发送命令，NM开启MRAPPMaster进程。
6.MR初始化job。
7.获取3中写入到HDFS中的输入分片。
 每个输入分片会创建一个map任务对象
 8.拿到输入分片后向RM的资源调度器请求分配资源来运行map、reduce task。
9.一旦RM的资源调度器为任务分配了container，AM就通过与NM通信来启动container。
10.该任务由主类为YarnChild的Java进程执行。但是它在运行之前会将需要的资源文件本地化。这里就会去HDFS获取程序运行所需的相关文件。
 在3中补充提到与框架无关的文件需要用户自己去上传和下载。文件是存放在HDFS上，依赖Hadoop的分布式缓存机制进行上传和下载。达到的效果是把用户需要使用的文件分发到各个NM节点。
 11.运行map任务或者reduce任务。
MapReduce模型  图片来自 https://blog.csdn.net/aijiudu/article/details/72353510
 Map阶段 1.输入文件进行split成小文件，被每个map任务使用。
2.由程序内的InputFormat(默认实现类TextInputFormat)来读取外部数据，它会调用RecordReader(它的成员变量)的read()方法来读取，返回k,v键值对。k,v键值对传送给map()方法，作为其入参来执行用户定义的map逻辑。
 MapReduce框架默认实现
 3.map()方法输出结果也是k,v键值对。对于map输出的每一个键值对，系统都会给定一个partition，partition值默认是通过计算key的hash值后对Reduce task的数量取模获得。如果一个键值对的partition值为1，意味着这个键值对会交给第一个Reducer处理。用户可以自定义partition逻辑。
4.Map的输出结果是由collector处理的，每个Map任务不断地将键值对输出到在内存中构造的一个环形数据结构中。使用环形数据结构是为了更有效地使用内存空间，在内存中放置尽可能多的数据。环形缓冲区其实就是一个数组，后端不断接受数据的同时，前端数据不断被溢出，长度用完后读取的新数据再从前端开始覆盖。这个缓冲区默认大小100M，可以通过MR.SORT.MB(应该是它)配置。
5.Map按照定义的partitioner分区，每个分区的输出value进行sort排序。
 若有combiner会先执行combiner。combiner作用是预合并，减少输出文件数量和大小。sort也是为了后面merge时效率更高。
 6.按照定义的partitioner分区spill(溢出)到文件，这些文件仍在map task所处机器上。
7.小文件执行merge(合并)，形成partitioner分区内有序的大文件。这些大文件仍在map task所处机器上。
 这里输出的文件可以选择使用压缩。
 Reduce阶段 1.copy数据。Reduce从AM那边获取本Reduce的数据存放在哪些Map里，到对应的Map机器去拉取文件。数据被reduce提走之后，map机器不会立刻删除数据，这是为了预防reduce任务失败需要重做。因此map输出数据是在整个作业完成之后才被删除掉的。
2.Merge、Sort、spill。这个过程与Map阶段类似，reduce将copy过来的数据文件加载到内存，进行merge和sort，当内存缓冲区的使用达到阈值后开始往磁盘spill。这个过程会循环多次，最终得到一份有序的reduce输入看k,v键值对文件。
3.通过GroupingComparator()分辨同一组的数据，把他们发送给reduce(k,iterator)方法。
4.调用context.write()方法，会让OutPurFormat调用RecodeWriter的write()方法将处理结果写入到数据仓库中。
 如何输出，输出到哪，都可以在RecodeWriter里自定义。
 Shuffle 这里将一下shuffle。这个阶段是MapReduce框架中间过程数据混洗阶段，交叉在map和reduce的过程中，包括数据分区，排序，局部聚合，缓存，拉取，再合并排序等阶段。从Map阶段的3~7以及Reduce阶段的1~2都是shuffle阶段。
HDFS Hadoop Distributed File System(hadoop分布式文件系统)，架构图如下。
有四部分组成
Client 职责：
 文件切分。文件上传 HDFS 的时候，Client 将文件切分成 一个一个的Block，然后进行存储。
 与 NameNode 交互，获取文件的位置信息。
 与 DataNode 交互，读取或者写入数据。
 Client 提供一些命令来管理 HDFS，比如启动或者关闭HDFS。
 Client 可以通过一些命令来访问 HDFS。
  NameNode 名称节点，是负责管理分布式文件系统的命名空间（Namespace），保存了两个核心的数据结构，即FsImage和EditLog。 你可以把它理解成大管家，它不负责存储具体的数据。
 FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据 操作日志文件EditLog中记录了所有针对文件的创建、删除、重命名等操作 注意，这个两个都是文件，也会加载解析到内存中。  职责：
 管理 HDFS 的名称空间
 管理数据块（Block）映射信息
 配置副本策略
 处理客户端读写请求。
  SendaryNamenode NameNode节点的备份，它会定期的和namenode就行通信来完成整个的备份操作。并非 NameNode 的热备。当NameNode 挂掉的时候，它并不能马上替换 NameNode 并提供服务。
职责：
 辅助 NameNode，分担其工作量。
 定期合并 fsimage和fsedits，并推送给NameNode。
 在紧急情况下，可辅助恢复 NameNode。
  DataNode 数据节点，用来具体的存储文件，维护了blockId 与 datanode本地文件的映射。 需要不断的与namenode节点通信，来告知其自己的信息，方便nameode来管控整个系统。
数据节点存储数据以块为单位，块大小默认是128m，默认会存储多份。
职责：
 存储实际的数据块。 执行数据块的读/写操作。  Hadoop集群节点组成 Hadoop集群逻辑节点组成 包括HDFS集群和YARN框架集群：
 HDFS集群  NameNode
SecondNameNode
DataNode
 YARN框架集群  ResourceManageNode
NodeManageNode
Hadoop集群物理节点应该如何分配？ 例如一套5节点的Hadoop集群：
节点1部署NameNode和ResourceManageNode。一般NameNode和ResourceManageNode部署在同一个节点上，这个节点为主节点。client node也在这个节点上；
节点2，3，4，5部署DataNode和NodeManageNode；
节点2部署SecondNameNode。
EMR集群介绍 EMR是AWS提供的Hadoop集群服务。现在使用云服务是主流趋势，这里介绍一下EMR集群节点组成。
 Master node  该节点管理集群，它通过运行软件组件来协调在其他节点之间分配数据和任务的过程以便进行处理。主节点跟踪任务的状态并监控集群的健康状况。每个集群具有一个主节点，并且可以创建仅包含主节点的单节点集群。
 Core node  该节点具有运行任务并在集群上的 Hadoop 分布式文件系统 (HDFS) 中存储数据的软件组件。多节点集群至少具有一个核心节点。
 Task node  该节点具有仅运行任务但不在 HDFS 中存储数据的软件组件。任务节点是可选的。
 参考文章
https://blog.csdn.net/aijiudu/article/details/72353510
https://blog.csdn.net/qianbing11/article/details/82357033
https://blog.csdn.net/xiaoshunzi111/article/details/48810239
https://blog.csdn.net/weixin_38750084/article/details/82963235
</content>
    </entry>
    
     <entry>
        <title>solr suggest实战</title>
        <url>https://jasonqian10.github.io/post/solr-suggest/</url>
        <categories>
          <category>Search</category>
        </categories>
        <tags>
          <tag>solr</tag><tag>lucene</tag>
        </tags>
        <content type="html"> solr suggest模块介绍 介绍 自动提示功能在现今的互联网产品中的应用几乎遍地都是。比如在京东主页搜索”苹果“，输入框下面就会自动联想出与苹果相关的关键词。
本文我们主要就来讲一下solr里面是如何去实现这样的自动提示功能。
Solr 中是通过 SuggestComponent 模块 为用户提供查询 term 的自动提示。可以使用此功能在搜索应用程序中实现强大的自动提示功能。
如何使用suggest模块 使用方式 先来介绍一下官方给出的使用方式，在solrconfig.xml中添加如下配置
&amp;lt;searchComponent name=&amp;#34;suggest&amp;#34; class=&amp;#34;solr.SuggestComponent&amp;#34;&amp;gt; &amp;lt;lst name=&amp;#34;suggester&amp;#34;&amp;gt; &amp;lt;str name=&amp;#34;name&amp;#34;&amp;gt;mySuggester&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;lookupImpl&amp;#34;&amp;gt;FuzzyLookupFactory&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;dictionaryImpl&amp;#34;&amp;gt;DocumentDictionaryFactory&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;field&amp;#34;&amp;gt;cat&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;weightField&amp;#34;&amp;gt;price&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;suggestAnalyzerFieldType&amp;#34;&amp;gt;string&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;buildOnStartup&amp;#34;&amp;gt;false&amp;lt;/str&amp;gt; &amp;lt;/lst&amp;gt; &amp;lt;/searchComponent&amp;gt; 解释一下上面配置中参数的含义
 searchComponent   如何定制 上面讲的是官方给出的使用方式，当然使用上面的配置，能实现基本的suggest功能。下面讲讲我的项目中是如何定制suggest的。下面分别介绍我参与的两个项目的suggest模块：
关键字自动提示 &amp;lt;searchComponent name=&amp;#34;suggest&amp;#34; class=&amp;#34;solr.SuggestComponent&amp;#34; enable=&amp;#34;true&amp;#34;&amp;gt; &amp;lt;lst name=&amp;#34;suggester&amp;#34;&amp;gt; &amp;lt;str name=&amp;#34;name&amp;#34;&amp;gt;default&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;lookupImpl&amp;#34;&amp;gt;AnalyzingInfixLookupFactory&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;indexPath&amp;#34;&amp;gt;infix_keyword&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;highlight&amp;#34;&amp;gt;false&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;dictionaryImpl&amp;#34;&amp;gt;DocumentDictionaryFactory&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;field&amp;#34;&amp;gt;TERM&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;weightField&amp;#34;&amp;gt;DF&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;sortField&amp;#34;&amp;gt;DF&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;suggestAnalyzerFieldType&amp;#34;&amp;gt;text_suggest&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;buildOnStartup&amp;#34;&amp;gt;false&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;buildOnCommit&amp;#34;&amp;gt;false&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;buildOnOptimize&amp;#34;&amp;gt;true&amp;lt;/str&amp;gt; &amp;lt;/lst&amp;gt; &amp;lt;/searchComponent&amp;gt; 公司名自动提示</content>
    </entry>
    
     <entry>
        <title>solr搜索原理解析</title>
        <url>https://jasonqian10.github.io/post/solr-lucene-principle/</url>
        <categories>
          <category>Search</category>
        </categories>
        <tags>
          <tag>solr</tag><tag>lucene</tag>
        </tags>
        <content type="html"> solr与Lucene的关系 讲搜索流程之前先介绍一下solr与Lucene的关系。
Lucene是一个索引与搜索类库，而不是完整的程序。使用Lucene的方式主要有二种：一是自己编写程序，调用类库；二是使用第三方基于Lucene编写的程序，如下面介绍的Solr等。
Solr 是一个开源的搜索服务器，Solr 使用 Java 语言开发，主要基于 HTTP 和 Apache Lucene 实现。Solr是在Lucene上封装的完善的搜索引擎。
solr是门户，lucene是底层基础。通俗地说，如果Solr是汽车，那么Lucene就是发动机，没有发动机，汽车就没法运转，但对于用户来说只可开车，不能开发动机。
solr搜索流程分solr部分和Lucene部分，整体流程是请求先经过solr部分再进入Lucene部分。  说明 对应网上已有的素材或者文字符合作者想要的描述，就直接引用了，不重复造轮子
参考 https://www.cnblogs.com/forfuture1978/archive/2010/04/04/1704282.html
https://www.cnblogs.com/davidwang456/p/10570935.html https://blog.csdn.net/huangzhilin2015/article/details/89372127
 solr的启动过程 Solr可以独立运行，运行在Jetty中，Jetty 是一个开源的servlet容器，它为基于Java的web容器，其工作流程（也就是solr server启动过程）如下 这属于servlet范畴，本文不重点讨论，大家知道大体流程即可。
solr query流程 solr处理query的入口是SolrDispatchFilter，其实现了javax.servlet的Filter的接口。通过拦截servlet请求的方式进入solr处理。 上图可以看出solr中的流程。下面按照处理顺序重点讲一下solr几个处理query的核心类：
SearchHandler 真正处理请求的入口函数在SearchHandler.handleRequestBody()。对于不同的Request-Handler(qt)，请求会进入不同的SearchHandler，这由solrconfig.xml中的配置决定。我们这里以 select 请求为例，请求会进入SearchHandler。handleRequestBody()中主要做的事情就是依次调用SearchComponent列表的prepare，process，post方法。  如何定制SearchHandler   当然可以定制自己的Request-Handler，继承SearchHandler或RequestHandlerBase都可以。然后在solrconfig.xml中标签中配置自己开发的类。例如自定义TestSearchHandler，url path为/test，则样例配置如下
&amp;lt;requestHandler name=&amp;#34;/test&amp;#34; class=&amp;#34;com.test.TestSearchHandler&amp;#34;&amp;gt; &amp;lt;lst name=&amp;#34;defaults&amp;#34;&amp;gt; &amp;lt;int name=&amp;#34;timeAllowed&amp;#34;&amp;gt;11000&amp;lt;/int&amp;gt; &amp;lt;str name=&amp;#34;echoParams&amp;#34;&amp;gt;none&amp;lt;/str&amp;gt; &amp;lt;int name=&amp;#34;rows&amp;#34;&amp;gt;20&amp;lt;/int&amp;gt; &amp;lt;str name=&amp;#34;defType&amp;#34;&amp;gt;xxx&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;op&amp;#34;&amp;gt;AND&amp;lt;/str&amp;gt; &amp;lt;float name=&amp;#34;tie&amp;#34;&amp;gt;1&amp;lt;/float&amp;gt; &amp;lt;str name=&amp;#34;qf&amp;#34;&amp;gt;xxxxx&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;fl&amp;#34;&amp;gt;xxxxx&amp;lt;/str&amp;gt; &amp;lt;str name=&amp;#34;sort&amp;#34;&amp;gt;score desc,_version_ desc&amp;lt;/str&amp;gt; &amp;lt;/lst&amp;gt; &amp;lt;/requestHandler&amp;gt; SearchComponent 初始化的时候SearchHandler中注册了本SearchHandler对应的SearchComponent的列表。一般包含主要功能的QueryComponent、FacetComponent、HighlightComponent、DebugComponent等，这些Component类都是继承SearchComponent这个抽象类。
SearchComponent抽象类定义了三个阶段prepare，process，post，SearchHandler.handleRequestBody()中会遍历所有注册的SearchComponent，调用这三个阶段，完成各个SearchComponent中功能。
 如何定制SearchComponent   定制SearchComponent的方法与定制SearchHandler的方法类似。继承SearchComponent或者对应功能的SearchComponent（如QueryComponent、FacetComponent、HighlightComponent、DebugComponent等）。然后在solrconfig.xml中标签配置自己开发的类。样例配置如下
&amp;lt;searchComponent name=&amp;#34;test_componet&amp;#34; class=&amp;#34;com.test.solr.TestComponent&amp;#34;&amp;gt; xxxxxx 里面可以配置自定义的参数 &amp;lt;/searchComponent&amp;gt; QueryComponet 进入查询最核心的QueryComponent，solr查询请求功能都是在本类中完成。 &#43; QueryComponent.prepare()
根据参数defType(配置在solrconfig.xml中标签中，不配置的话默认是”lucene“)，初始化QParser以及Query。以defType=”lucene“为例，其初始化过程如下
1.QParser parser = QParser.getParser(rb.getQueryString(), defType, req) 2.LuceneQParserPlugin.createParser(qstr, localParams, req.getParams(), req) 3.new LuceneQParser(qstr, localParams, params, req); 4.Query query = LuceneQParser.parse()  补充：QParser类与QParserPlugin类 QParser类的作用是QParser.parse() 可以构造出Query对象，查询时必须使用的对象。QParser一般由QParserPlugin.createParser()创建。QParser类与QParserPlugin类都是抽象类，不同的defType参数，对应不同的实现类。以defType=”lucene“为例，其初始化过程如下
  QueryComponent.process()   process()主要调用SolrIndexSearcher.search()，主要工作都在search()中完成。
 SolrIndexSearcher类继承IndexSearcher，对InderSearch做了封装。最终调用IndexSearcher.search()函数。 这是Lucene处理query的入口。
 Lucene query流程 Lucene处理query的入口是IndexSearcher.search()。其调用流程如下 createNormalizedWeight 创建归一化weight的流程，包括
重写Query对象 代码为：query = rewrite(query)
这个rewrite()作用是将 2.3 节中QParse.parse()解析出的Query对象转换成Query对象树，这棵树很重要，从Query对象树——》Weight对象树——》Scorer对象树，一直贯穿整个索引过程。为什么需要rewrite？ 因为solr很多不同的查询类型，比如前缀查询和通配符查询，从本质上，任何的查询都可以视为对多个关键词的查询。整个重写过程是把从Lucene角度认为原始的、开销大的查询对象转变成一系列开销小的查询对象的一个过程。
举个例子，查询语句 Title:(car* or bike) ，其QParse.parse()解析出的Query对象结构为
BooleanQuery(Title:(car* or bike)) &#43; BooleanQuery(Title:(car* or bike)) &#43; PrefixQuery(Title:car*) &#43; TermQuery(Title:or) --这个BooleanClause后面流程会继续处理掉 &#43; TermQuery(Title:bike) rewrite Query之后为
BooleanQuery(Title:(car* or bike)) &#43; MultiTermQueryConstantScoreWrapper(Title:car*) &#43; PrefixQuery(Title:car*) &#43; TermQuery(Title:or) --这个BooleanClause后面流程会继续处理掉 &#43; TermQuery(Title:bike) 对于PrefixQuery和FuzzyQuery，这些查询语句由于特殊的语法，可能对应的不是一个词，而是多个词，因而他们都有rewriteMethod对象指向MultiTermQuery的Inner Class，表示对应多个词，在查询过程中会得到特殊处理。
创建weight 调用 Query.createWeight(Searcher) 创建weight，以3.1.1中BooleanQuery为例，代码为
BooleanQuery.createWeight(Searcher) ... return new BooleanWeight(searcher) BooleanWeight构造函数主要实现是递归遍历Query树，生成Weight树。遍历过程中叶子节点是TermQuery，其TermQuery.createWeight(Searcher) 返回return new TermWeight(searcher)对象。在TermWeight构造函数中，需要做几件事：
 获取Similarity类
this.similarity = searcher.getSimilarity(needsScores); Similarity类是Lucene的相似度类（用于计算文档分数），嵌套在Weight对象中，Weight对象嵌套在Query对象中。这样Query树中每个query节点都会构造自己的打分类。 &amp;gt; 补充： &amp;gt; searcher.getSimilarity() 获取的Similarity对象是在初始化solr时创建的，根据schema.xml中是否定义了Similarity类，如果定义了，则用用户自定义的Similarity类进行打分，如果没有自定义，则使用solr默认的打分类BM25Similarity。后面的文章会详细介绍如何自定义打分。
 计算idf
this.stats = similarity.computeWeight(collectionStats, termStats); 这里 this.stats 对象已经计算好idf值。
   Lucene打分使用TF-IDF的打分公式，idf是其中一项。这里不详细介绍。
 计算分数 代码为
float v = weight.getValueForNormalization(); float norm = getSimilarity(needsScores).queryNorm(v); weight.normalize(norm, 1.0f); 这步计算的TF-IDF打分公式中仅与搜索语句相关与文档无关的部分(即不依赖于查询结果)，每个query子对象分数都是一样。分数存在weight对象中，在最终打分时可以直接使用。因为与文档无关，无需收集文档时遍历每篇文档重复计算，这里计算好，后面重复使用。
收集(collect)文档和打分(score) 收集文档 文档收集是收集匹配query的文档集，这里重点介绍涉及的几个类。  文档收集器（Collector及其实现类） 如上图Collector类是文档收集器接口类，其getLeafCollector()方法来获取LeafCollector对象（段文档收集器）。 TopDocsCollector类是个抽象类，实现了Collector接口，是一个文档收集器基类。其有个TopScoreDocCollector#create方法用于创建文档收集器对象，这个创建出来的对象一般是TopScoreDocCollector的子类。 SimpleTopScoreDocCollector类，是TopScoreDocCollector的子类，也是其内部类，是简单查询文档收集器。 PagingTopScoreDocCollector类，是TopScoreDocCollector的子类，也是其内部类，是用于分页查询文档收集器。
 段文档收集器（LeafCollector类及其实现类） LeafCollector是段文档收集器接口，LeafCollector#collect 方法最终完成收集文档的工作。段文档收集器会被Collector#getLeafCollector 初始化，包装在文档收集器中。这里会用到其子类ScorerLeafCollector。
  介绍好了这几个类之后，开始讲收集文档的过程。首先还在2.3步的时候，SolrIndexSearcher.search()方法里会调用SolrIndexSearcher#getDocListNC方法，在该方法中调用
final TopDocsCollector topCollector = buildTopDocsCollector(len, cmd); SolrIndexSearcher#buildTopDocsCollector方法中调用
TopScoreDocCollector.create(weightedSort, len, searchAfter, fillFields, needScores, needScores); 注意：当query参数中存在sort字段是会用。这里以上面的为例。 TopFieldCollector.create(weightedSort, len, searchAfter, fillFields, needScores, needScores); 这个方法在上面介绍TopScoreDocCollector类的时候提过到。TopScoreDocCollector#create中会创建TopScoreDocCollector的子类。当简单查询时创建SimpleTopScoreDocCollector，分页查询时创建PagingTopScoreDocCollector。
1. new SimpleTopScoreDocCollector(numHits); 2. new PagingTopScoreDocCollector(numHits, after); 然后会接下去会调用IndexSearcher#search(List leaves, Weight weight, Collector collector)方法，该方法的处理逻辑是for循环每个段，执行
leafCollector = collector.getLeafCollector(ctx); 获取段文档收集器对象leafCollector，这里的collector就是上面创建的SimpleTopScoreDocCollector类对象。
创建Scorer树 Scorer类是Lucene实现打分的类，是个抽象类，每个Query子类都会集成Scorer类，作为每个Query打分的入口。如TermQuery的Scorer类是TermScorer，TermQuery打分的入口则是TermScorer#score()。
创建Scorer树入口代码：
BulkScorer scorer = weight.bulkScorer(ctx) 创建Scorer对象树的过程其实与创建Weight对象树的过程类似。遍历Weight树依次创建Scorer对象。以TermQuery对象为例，初始化关键代码：
1.Scorer scorer = TermWeight.scorer() 2.return new TermScorer(this, docs, similarity.simScorer(stats, context)); 创建TermScorer时传入了SimScorer对象，由Similarity#simScorer获取而来，Similarity类的对象，在创建TermQuery时维护在对象内部。
similarity.simScorer(stats, context) SimScorer类是Similarity类的内部类，具体打分逻辑就是SimScorer#score()方法中实现。TermScorer对象初始化时会在对象内部维护SimScorer对象。打分时调用顺序会是： TermScorer.score() ——》 SimScorer.score()
打分score 打分入口是BulkScorer#score()方法
scorer.score(leafCollector, ctx.reader().getLiveDocs()); 进入Weight#score()方法，这里会执行
collector.setScorer(scorer); 为收集器对象传入scorer打分对象（这个scorer对象会最终被LeafCollector#collect中使用来进行打分）。 调用Weight#scoreAll()方法，这里会调用DocIdSetIterator#nextDoc()方法，DocIdSetIterator是个迭代器，依次拿出匹配到的文档id。
int doc = iterator.nextDoc()  至于如何拿出这些匹配到文档id，过程比较复杂，涉及Lucene索引文件相关的原理，后面文章会细聊。
 这里需要注意，每个段拿出的文档id是基于本段的排序。而最终的文档id是需要全局唯一的，这里需要加上docBase。
final int docBase = context.docBase; pqTop.doc = doc &#43; docBase; 然后传入拿出的文档id，调用段文档收集器LeafCollector#collect 方法
collector.collect(doc); 然后进入 TermScorer.score() ——》 SimScorer.score()完成打分。
</content>
    </entry>
    
</search>